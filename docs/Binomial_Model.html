<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.433">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Adrien Osakwe">

<title>Bayesian Inference - 3&nbsp; Introduction</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./Conjugate_Dist.html" rel="next">
<link href="./Main.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./Binomial_Model.html"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Introduction</span></a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Bayesian Inference</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Index</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Main.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Bayesian Inference Projects</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Binomial_Model.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./Conjugate_Dist.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Conjugate Distributions</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./PosteriorSummary.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Studying the Posterior</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./LikelihoodConsiderations.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Likelihood Considerations</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./OptimalDecisionMaking.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Optimal Decision Making</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./PosteriorApproximation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Approximation and Sampling Methods</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./BayesianModels.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Bayesian Modelling</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./BayesianNonParametric.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Bayesian Non-parametrics</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./PracticeProblems.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Exercises</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#binomial-model" id="toc-binomial-model" class="nav-link active" data-scroll-target="#binomial-model"><span class="header-section-number">3.1</span> Binomial Model</a>
  <ul class="collapse">
  <li><a href="#maximum-likelihood" id="toc-maximum-likelihood" class="nav-link" data-scroll-target="#maximum-likelihood"><span class="header-section-number">3.1.1</span> Maximum Likelihood</a></li>
  <li><a href="#bayesian-model" id="toc-bayesian-model" class="nav-link" data-scroll-target="#bayesian-model"><span class="header-section-number">3.1.2</span> Bayesian Model</a></li>
  <li><a href="#components-of-bayesian-inference" id="toc-components-of-bayesian-inference" class="nav-link" data-scroll-target="#components-of-bayesian-inference"><span class="header-section-number">3.1.3</span> Components of Bayesian Inference</a></li>
  <li><a href="#prediction" id="toc-prediction" class="nav-link" data-scroll-target="#prediction"><span class="header-section-number">3.1.4</span> Prediction</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Introduction</span></h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Adrien Osakwe </p>
          </div>
  </div>
    
  
    
  </div>
  

</header>

<section id="binomial-model" class="level2" data-number="3.1">
<h2 data-number="3.1" class="anchored" data-anchor-id="binomial-model"><span class="header-section-number">3.1</span> Binomial Model</h2>
<p>Here I will explore the binomial model, where each random variable represents a success (1) or failure (0) of a trial. The usual example is coin tossing, which, unless an unfair coin is used, always has a probability of 0.5 for landing a head or tail. It is therefore more interesting to explore a problem such as the thumbtack toss, where the ground truth probability of success (landing with the point up) is less well defined.</p>
<p>We can assume <em>n</em> trials are done and count the total number of trials where the point lands up (<span class="math inline">\(s_n\)</span> ) to find an approximation of the ground truth for the probability of success <span class="math inline">\(\theta\)</span> . A feasible approach to estimating <span class="math inline">\(\theta\)</span> would be to divide the number of success <span class="math inline">\(s_n\)</span> by the number of trials <span class="math inline">\(n\)</span>:</p>
<p><span class="math display">\[
\theta = \frac{s_n}{n}
\]</span></p>
<p>However, this estimation is only meaningful for large n and provides no estimate of the <em>uncertainty</em> of the measurement. Hence, the field of <em>statistical inference</em> becomes relevant as the latter can be achieved by creating a model for the problem.</p>
<section id="generate-data" class="level4" data-number="3.1.0.1">
<h4 data-number="3.1.0.1" class="anchored" data-anchor-id="generate-data"><span class="header-section-number">3.1.0.1</span> Generate Data</h4>
<p>To create the model, we first generate data by tossing the thumbtack say, 25 times (<span class="math inline">\(n = 25\)</span>). We can then present the problem as a binomial model where:</p>
<p><span class="math display">\[
s_n \sim Bin(n,\theta)
\]</span></p>
<p>which takes the form:</p>
<p><span class="math display">\[
f(s_n;n,\theta) = \binom{n}{s_n}\theta^{s_n}(1-\theta)^{n-s_n}
\]</span></p>
<div class="cell">
<div class="cell-output-display">
<p><img src="Binomial_Model_files/figure-html/unnamed-chunk-1-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>The above plot shows how the choice of <span class="math inline">\(\theta\)</span> affects the overall distribution. From here, we can try to infer the true value of theta using a <em>frequentist</em> or <em>Bayesian</em> approach.</p>
</section>
<section id="maximum-likelihood" class="level3" data-number="3.1.1">
<h3 data-number="3.1.1" class="anchored" data-anchor-id="maximum-likelihood"><span class="header-section-number">3.1.1</span> Maximum Likelihood</h3>
<p>The frequentist approach relies on what is called the likelihood: the probability that the distribution has a certain parameter given the data we collected. From this equation we try to find the maximum likelihood. That is, we try to find the parameter that <em>maximizes</em> the likelihood for the data we collected. For our binomial model, we then have:</p>
<p><span class="math display">\[
\hat{\theta}(s_n) = \underset{\theta}{argmax}L(\theta;s_n)
\]</span></p>
<p>where</p>
<p><span class="math display">\[
L(\theta;s_n)
\]</span></p>
<p>is the likelihood function we are maximizing.</p>
<p>For convenience, the likelihood is often expressed as a <em>log-likelihood</em> which is usually easier to compute. The first step is to ignore the normalizing constant, as it does not depend on <span class="math inline">\(\theta\)</span> . We then have:</p>
<p><span class="math display">\[
l(\theta;s_n) = logL(\theta;s_n)
\]</span></p>
<p><span class="math display">\[
= logf(s_n;n,\theta) \propto  log(\theta^{s_n}(1-\theta)^{n-s_n})
\]</span></p>
<p><span class="math display">\[
= s_nlog\theta + (n-s_n)log(1-\theta)
\]</span></p>
<p>Differentiating the equation helps us identify the extreme values:</p>
<p><span class="math display">\[
l'(\theta;s_n) = \frac{s_n}{\theta} - \frac{n-s_n}{1-\theta} = 0
\]</span></p>
<p><span class="math display">\[
= s_n-s_n\theta - n\theta + s_n\theta = s_n -n\theta
\]</span></p>
<p><span class="math display">\[
\theta = \frac{s_n}{n}
\]</span></p>
<div class="cell">
<div class="cell-output-display">
<p><img src="Binomial_Model_files/figure-html/unnamed-chunk-2-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>We can also use the second derivative which is always negative, indicating that the log-likelihood is concave and that the extreme value is a global maximum.</p>
<p>Although this approach gives us an estimate of the model parameters, there is no indication of our <em>confidence</em> in the result and on the likelihood of other parameter values. This is due to the frequentist approach treating <span class="math inline">\(\theta\)</span> as a constant as opposed to an unknown random variable.</p>
<p>This is circumvented by calculating the maximum likelihood estimates from all observable data sets. In this case, we are observing the random variable <span class="math inline">\(S_n\)</span> as opposed to the constant <span class="math inline">\(s_n\)</span> and have the following *maximum likelihood estimate:</p>
<p><span class="math display">\[ \hat{\theta}(Y) = \frac{Y}{n}\]</span></p>
<p>We can then estimate the standard error and construct confidence intervals for our parameter values. Hypothesis testing is also a possibility.</p>
<p><em>Note: fill out an example showing how to get the above.</em></p>
</section>
<section id="bayesian-model" class="level3" data-number="3.1.2">
<h3 data-number="3.1.2" class="anchored" data-anchor-id="bayesian-model"><span class="header-section-number">3.1.2</span> Bayesian Model</h3>
<p>In the Bayesian framework, we treat the distribution parameters as random variables. We are first interested in knowing what the probability of the thumbtack landing upwards is <em>prior</em> to tossing any. This prior essentially defines the distribution from which our parameter <span class="math inline">\(\theta\)</span> is sampled from. For example, we can set this to be a beta distribution:</p>
<p><span class="math display">\[
\theta  \sim Beta(\alpha,\beta)
\]</span></p>
<p>We can also formulate the <em>sampling distribution</em> which is the distribution of the data <em>given</em> the parameter. It is denoted as follows:</p>
<p><span class="math display">\[
f_{S_n|\Theta}(s_n | \theta)
\]</span> This notation emphasizes that the sampling distribution is a <em>conditional</em> probability distribution. We therefore have a model composed of the following prior and sampling distributions: <span class="math display">\[
S_n|\theta \sim Bin(n,\theta)
\]</span></p>
<p><span class="math display">\[
\theta \sim Beta(\alpha,\beta)
\]</span> With this tools, we can now focus on updating our parameter estimates based on observed data. This step is what has us compute the so-called <em>posterior</em> distribution of the parameter. We start with:</p>
<p><span class="math display">\[
f_{\theta,\S_n}(\theta,s_n) = f_{\theta|S_n}(\theta|s_n)f_{S_n}(s_n)
\]</span> <span class="math display">\[
f_{\theta|S_n}(\theta|s_n) = f_{\theta,\S_n}(\theta,s_n)/f_{S_n}(s_n)
\]</span> <span class="math display">\[
f_{\theta|S_n}(\theta|s_n) = \frac{f_{\theta}(\theta)f_{\S_n|\theta}(s_n|\theta)}{f_{S_n}(s_n)}
\]</span> As the denominator on the RHS has no dependence on <span class="math inline">\(\theta\)</span>, it can be ignored and the posterior can be seen as proportional to the joint distribution (the numerator):</p>
<p><span class="math display">\[
f_{\theta|S_n}(\theta|s_n) \propto f_{\theta}(\theta)f_{\S_n|\theta}(s_n|\theta) = \frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha)\Gamma(\beta)}\theta^{\alpha - 1}(1-\theta)^{\beta - 1} * \binom{n}{s_n}\theta^{s_n}(1-\theta)^{n-s_n}
\]</span> <span class="math display">\[
\propto \theta^{s_n + \alpha_0 - 1}(1-\theta)^{n-s_n + \beta_0 - 1}
\]</span></p>
<p>This derivation is similar in form to the beta distribution given the following, new representation of the posterior:</p>
<p><span class="math display">\[
\Theta|S_n \sim Beta(s_n + \alpha_0, n - s_n + \beta_0)
\]</span> We can now compare the prior and posterior:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">25</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>sn <span class="ot">&lt;-</span> <span class="dv">15</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>a <span class="ot">&lt;-</span> <span class="dv">2</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>b <span class="ot">&lt;-</span> <span class="dv">3</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>a_n <span class="ot">&lt;-</span> a <span class="sc">+</span> sn</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>b_n <span class="ot">&lt;-</span> n <span class="sc">-</span> sn <span class="sc">+</span> b</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>thetas <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="dv">0</span>,<span class="dv">1</span>,<span class="fl">0.01</span>)</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>prior <span class="ot">&lt;-</span> <span class="fu">dbeta</span>(thetas,a,b)</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>posterior <span class="ot">&lt;-</span> <span class="fu">dbeta</span>(thetas,a_n,b_n)</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(thetas,prior, <span class="at">xlab =</span> <span class="st">'Theta Value'</span>,<span class="at">ylab =</span> <span class="st">'f(Theta)'</span>,</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>     <span class="at">col =</span> <span class="st">'blue'</span>,<span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="fu">max</span>(posterior)),</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>     <span class="at">type =</span> <span class="st">'l'</span>)</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(thetas,posterior, <span class="at">col =</span> <span class="st">'red'</span>)</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">'topleft'</span>,<span class="at">inset =</span> <span class="fl">0.02</span>,<span class="at">legend =</span> <span class="fu">c</span>(<span class="st">'Beta(a,b)'</span>,<span class="st">'Beta(a_n,b_n)'</span>),</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>       <span class="at">col =</span> <span class="fu">c</span>(<span class="st">'blue'</span>,<span class="st">'red'</span>),</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>       <span class="at">lwd =</span> <span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="Binomial_Model_files/figure-html/unnamed-chunk-3-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>This reveals that the true value of theta (given the observed trials) is most likely between ~ 0.4 and 0.8.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="fu">pbeta</span>(<span class="fl">0.8</span>,a_n,b_n) <span class="sc">-</span> <span class="fu">pbeta</span>(<span class="fl">0.4</span>,a_n,b_n) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.9649619</code></pre>
</div>
</div>
<p>We can also calculate the <em>posterior mean</em> by finding the mean of the beta distribution we derived for the posterior</p>
<p><span class="math display">\[
E(\theta|S_n = s_n) = \frac{\alpha_n}{\alpha_n + \beta_n} = \frac{s_n + \alpha_0}{\alpha_0 + n + \beta_0} = \frac{17}{30}
\]</span></p>
</section>
<section id="components-of-bayesian-inference" class="level3" data-number="3.1.3">
<h3 data-number="3.1.3" class="anchored" data-anchor-id="components-of-bayesian-inference"><span class="header-section-number">3.1.3</span> Components of Bayesian Inference</h3>
<p>We can now generalize the example to highlight the key concepts for Bayesian inference.</p>
<p>We work on a problem with <em>observed</em> data coming from <em>n</em> observations which we can then use to create and update a model representing the <em>generative process</em> behind the data. Here, we will focus on parametric inference, where the observed data helps us better estimate the model parameters.</p>
<section id="sampling-distribution-and-the-likelihood-function" class="level4" data-number="3.1.3.1">
<h4 data-number="3.1.3.1" class="anchored" data-anchor-id="sampling-distribution-and-the-likelihood-function"><span class="header-section-number">3.1.3.1</span> Sampling Distribution and the Likelihood function</h4>
<p>The conditional distribution of the data given the parameter values, <span class="math display">\[f_{S_n|\Theta}(s_n|\theta)\]</span> , can be referred to as the sampling distribution or the likelihood function. The be exact, the sampling distribution presents the above as a function of the observed data, whereas the likelihood presents it as a function of the model parameters.</p>
<p>If we assume that our data is independent, given <span class="math display">\[\theta\]</span>, we can present the joint sampling distribution as a product of the sampling distributions for each random variable or trial:</p>
<p><span class="math display">\[
f_{S_N|\Theta}(s|\theta) = \prod_{i =1}^{N}f_{S_i|\Theta}(s_i|\theta)
\]</span></p>
<p>Which becomes even simpler if the observations ar i.i.d (not only independent, but coming from the same distribution):</p>
<p><span class="math display">\[
f_{S_N|\Theta}(s|\theta) = \prod_{i =1}^{N}f(s_i|\theta)
\]</span></p>
<p>Many different models can be used for the sampling distribution, but it is usually recommended to use models whose behavior best describes the observed phenomena (e.g.&nbsp;our thumbtack example is a clear success or failure scenario, which makes the binomial distribution suitable).</p>
</section>
<section id="prior-distribution" class="level4" data-number="3.1.3.2">
<h4 data-number="3.1.3.2" class="anchored" data-anchor-id="prior-distribution"><span class="header-section-number">3.1.3.2</span> Prior distribution</h4>
<p>The prior distribution represents the distribution from which the parameter values of the sampling distribution are generated. It represents our beliefs in the parameter values <em>prior</em> to observing any data.</p>
<p>In situations where there is little confidence in the possible values for the parameter, it is best to just a vague prior distribution to reduce its influence on the model and put a greater emphasis on the observed data (<em>uninformative prior</em>). We could also have an <em>informative prior</em> which has a greater influence on the model which can enforce sparsity on values we believe should be zero. We can also call the prior distribution a parametric distribution, which depends on <em>hyperparameters</em> (in the thumbtack case, these would be <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> ).</p>
<p><strong>Posterior distribution</strong></p>
<p>For the posterior, we make use of Bayes’ theorem to formulate it. The normalizing constant, which has no dependence on the parameter can be treated as a constant w.r.t. the parameter values and is often ignored. We can therefore compute the posterior as being <em>proportional</em> to the joint distribution.</p>
</section>
<section id="marginal-likelihood" class="level4" data-number="3.1.3.3">
<h4 data-number="3.1.3.3" class="anchored" data-anchor-id="marginal-likelihood"><span class="header-section-number">3.1.3.3</span> Marginal Likelihood</h4>
<p>The normalizing constant is also described as the <em>marginal likelihood</em>, as it represents the joint probability of the observed data after marginalizing out the parameter $\theta$. This presents itself as an integral in continuous cases and as a sum in discrete cases (for the parameter). This can also be seen as the expectation of the sampling distribution, where we average the values over the full sample space for <span class="math inline">\(\theta\)</span> .</p>
</section>
</section>
<section id="prediction" class="level3" data-number="3.1.4">
<h3 data-number="3.1.4" class="anchored" data-anchor-id="prediction"><span class="header-section-number">3.1.4</span> Prediction</h3>
<p>Beyond estimating the true parameter values, we are also interested in predicting the unobserved data (n + m). The simplest way to achieve this would be to use the MLE for the model parameters and predict the new data. This however, can lead to estimates that are biased if the observed data used for the MLE came from a small sample size (e.g.: only three tosses and all fell down). We can instead go the Bayesian route and compute a probability for the new observations <em>given</em> the observed data</p>
<p><span class="math display">\[
f_{\tilde{S}|S}(\tilde{s}|s)
\]</span></p>
<p>The parameter values aren’t present in the function, but it is important to realize that they are need to derive the predictive distribution. In essence, the posterior predictive distribution is calculated as the product of the sampling distribution for the new data and the <em>posterior</em> distribution from the observed data, which acts as un <em>updated prior distribution</em>. In essence, the same way we updated <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> for the observed data, we do it again by updating their updated values.</p>
<p><span class="math display">\[
f_{\tilde{S}|S_n}(\tilde{s}|s_n) = \int_{\Theta}
f_{\tilde{S}|\Theta}(\tilde{s}|\theta)f_{\theta|S_n}(\theta|s_n)
d\theta
\]</span></p>
<p><span class="math display">\[
f_{\tilde{S}|S_n}(\tilde{s}|s_n) = \int_{\Theta}\binom{m}{\tilde{s}}
\theta^{\tilde{s}}(1-\theta)^{m - \tilde{s}}
\frac{1}{B(\alpha_n,\beta_n)}
\theta^{\alpha_n - 1}(1-\theta)^{\beta_n - 1}d\theta
\]</span></p>
<p>Removing constants and recognizing the new formulation of a beta function, as in the earlier example, allows us to define the new posterior predictive function given the updated prior:</p>
<p><span class="math display">\[
f_{\tilde{S}|S_n}(\tilde{s}|s_n) = \binom{m}{\tilde{s}}\frac{B(\tilde{s} + \alpha_n,m + \beta_n - \tilde{s})}{B(\alpha_n,\beta_n)}
\]</span></p>
<p>Which represents the <strong>beta-binomial distribution</strong>. With this formulation we can therefore iteratively update our prior distribution as we collect more samples, leading to a progressively more accurate posterior predictive distribution.</p>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./Main.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Bayesian Inference Projects</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./Conjugate_Dist.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Conjugate Distributions</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>